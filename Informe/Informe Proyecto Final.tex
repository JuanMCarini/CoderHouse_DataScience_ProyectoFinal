\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}

\usepackage[top=2cm, bottom=1.5cm, right=1.5cm, left=2cm]{geometry}

\usepackage{graphicx}

\usepackage{hyperref}%Links
\hypersetup{  %formato link
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue}

\usepackage{float} %para fijar tablas
\usepackage{multirow} %Para tablas

\usepackage{csvsimple} %csv to table

\title{\textbf{CoderHouse \\ \vspace{0.5cm} Curso Data Science \\ \vspace{0.5cm} Informe del Proyecto Final\\ \vspace{0.5cm}
Análisis socioeducativo de los habitantes de la Ciudad de Buenos Aires}}

\author{\textbf{Profesor:} Damian Dapueto \\ \vspace{0.2cm} \textbf{Tutor:} Héctor Alonso \\ \vspace{0.2cm} \textbf{Grupo de Trabajo:} \\ Lucia Buzzeo, Lucia Hukovsky,\\ Jose Saint German, Juan Martín Carini}

\begin{document}

\maketitle

\begin{center}
    \includegraphics[scale=1.75]{Imagenes/Coder.png}
\end{center}
 
\thispagestyle{empty}
 
\newpage
 
\tableofcontents
 
\newpage

\section{Introducción}

    \subsection{Resumen del proyecto}

        La ciudadanía es un concepto jurídico, filosófico y político que ha sido creado para designar a una persona física que constituye una sociedad o entidad territorial. Para las personas que forman parte de una comunidad, ciudadanos, resulta de suma importancia sentirse representados por los demás integrantes de la misma, mediante políticas públicas que abarquen sus necesidades y requerimientos. 

        La toma de datos demográficos y la estadística son dos herramientas primordiales a la hora de identificar requerimientos de los integrantes de una comunidad. Dichas herramientas describen, de forma cuantitativa, a la sociedad bajo estudio. Precisamente, los censos y la estadística son la fuente primaria de información para la planificación económica y social de una población, por parte de sus representantes.

        En el caso particular de Argentina, el Instituto Nacional de Estadística y Censos (INDEC) es el organismo público que ejerce la dirección superior de todas las actividades estadísticas oficiales que se realizan en el país. La información que produce el INDEC es una herramienta básica para la planificación de políticas públicas, así como para las investigaciones y proyecciones que se realizan en los ámbitos académico y privado.

        Al adentrarse y estudiar los índices correspondientes a uno de los ejes principales, educación, en un territorio delimitado, Ciudad Autónoma de Buenos Aires, se ha encontrado una gran limitación relacionada con su acceso inequitativo para los diferentes actores de la sociedad. 

        Este hecho tiene consecuencias de índole social y económico para la población. Sin embargo, la principal problemática se da a nivel individual, y radica en el impedimento al acceso educativo para un porcentaje de la sociedad. Esto no ha resultado una novedad para el grupo, pero sí ha dado el pie a la búsqueda de una respuesta teórica a dicha disparidad, en concreto, a descubrir las principales variables que afectan el nivel educativo.

        El análisis realizado en el marco del presente proyecto podría establecer una base de requerimientos que permitan generar políticas públicas efectivas, no solo en el ámbito educativo, sino en el económico, cultural, social y geográfico, entre otros.

    \subsection{Objetivos del proyecto}

        En el presente proyecto se persigue el objetivo de descubrir las principales variables intervinientes en el nivel máximo educativo alcanzado por la población de la Ciudad Autónoma de Buenos Aires (CABA).
        
        En concreto, con este proyecto se plantea el análisis de variables que podrían contribuir al nivel máximo educativo alcanzado por cada individuo en CABA. Las mismas se estudian tanto de forma independiente como entrelazadas. El alcance de dicho objetivo permitiría identificar posibles causas que derivan en la desigualdad de acceso educativo, y, en última instancia, generar políticas públicas eficaces que permitan subsanar dicha problemática. 

    De este objetivo principal se desprenden los siguientes objetivos específicos:
    \begin{itemize}
        \item Determinar si la ubicación geográfica del encuestado es determinante para alcanzar ciertos niveles educativos. De este objetivo se desprende determinar la relación entre el nivel educativo y la comuna del encuestado, así como la relación entre la misma variable y el hecho de que el encuestado habite en una villa de emergencia.
        \item Establecer la fuerza con la que el nivel socioeconómico afecta la variable target.
        \item Explorar la relación del target con otras variables, como el sexo del encuestado, la cantidad de hijos, la afiliación de salud o la edad.
    \end{itemize}

    \subsection{Definición de la fuente de información}

        Para trabajar esta problemática, se ha recurrido a la Encuesta Anual de Hogares del Gobierno de la Ciudad de Buenos Aires para el año 2019. El dataset está disponible en la base de datos abiertos del GCBA.

        Esta encuesta contiene información demográfica, social, económica, educativa y de salud de 14319 habitantes de la Ciudad, la cual es una muestra representativa que permite obtener un vistazo de la población de la Ciudad.

\section{Planificación}

    \subsection*{Estructura de los trabajos}

    Este trabajo se ha dividido en 3 partes:
    \begin{enumerate}
        \item \textbf{Introducción a las variables del problema:} Se realiza un análisis de las variables del dataset. En el mismo se busca conocer su performance dentro del dataset. A la vez, se investiga cómo las variables interactúan entre sí. Esta parte es lo que se conoce como análisis univariado, bivariado y multivariado
        \item \textbf{Modelos análiticos:} En esta sección se llevan a cabo diversos modelos análiticos y algoritmos que sirven para alcanzar los objetivos seteados para el presente proyecto. Como la variable objetivo es categórica, se realizan diversos modelos de clasificación.
        \item \textbf{Conclusión:} Se alcanzan conclusiones finales sobre los hallazgos. Además, se discuten posibles limitaciones y se plantean futuras líneas de análisis, a partir del análisis presente.
        
    \end{enumerate}

\section{Introducción a las variables: Análisis exploratorio de los datos}
 
    Una ves cargado el dataset con el que vamos a trabajar, miramos sus variable, el tipo que son y si tienen nulls:
    \begin{table}[H]\begin{center}
    \begin{tabular}{clll}
    \multicolumn{4}{l}{RangeIndex: 14319 entries, 0 to 14318} \\
    \multicolumn{4}{l}{Data columns (total 31 columns):}  \\
    \#  & Column                     & Non-Null Count & Dtype \\ \hline
    0  & id                          & 14319 non-null & int64 \\
    1  & nhogar                      & 14319 non-null & int64 \\
    2  & miembro                     & 14319 non-null & int64 \\
    3  & comuna                      & 14319 non-null & int64 \\
    4  & dominio                     & 14319 non-null & object \\
    5  & edad                        & 14319 non-null & int64 \\
    6  & sexo                        & 14319 non-null & object \\
    7  & parentesco\_jefe             & 14319 non-null & object \\
    8  & situacion\_conyugal          & 14318 non-null & object \\
    9  & num\_miembro\_padre           & 14319 non-null & object \\
    10 & num\_miembro\_madre           & 14319 non-null & object \\
    11 & estado\_ocupacional          & 14319 non-null & object \\
    12 & cat\_ocupacional             & 14319 non-null & object \\
    13 & calidad\_ingresos\_lab        & 14319 non-null & object \\
    14 & ingreso\_total\_lab           & 14319 non-null & int64  \\
    15 & calidad\_ingresos\_no\_lab     & 14319 non-null & object \\
    16 & ingreso\_total\_no\_lab        & 14319 non-null & int64  \\
    17 & calidad\_ingresos\_totales    & 14319 non-null & object \\
    18 & ingresos\_totales            & 14319 non-null & int64  \\
    19 & calidad\_ingresos\_familiares & 14319 non-null & object \\
    20 & ingresos\_familiares         & 14319 non-null & int64  \\
    21 & ingreso\_per\_capita\_familiar & 14319 non-null & int64  \\
    22 & estado\_educativo            & 14319 non-null & object \\
    23 & sector\_educativo            & 14316 non-null & object \\
    24 & nivel\_actual                & 14319 non-null & object \\
    25 & nivel\_max\_educativo         & 13265 non-null & object \\
    26 & años\_escolaridad            & 14257 non-null & object \\
    27 & lugar\_nacimiento            & 14318 non-null & object \\
    28 & afiliacion\_salud            & 14315 non-null & object \\
    29 & hijos\_nacidos\_vivos         & 6535 non-null  & object \\
    30 & cantidad\_hijos\_nac\_vivos    & 14319 non-null & object \\
    \multicolumn{4}{l}{dtypes: int64(10), object(21)}  \\
    \multicolumn{4}{l}{memory usage: 3.4+ MB} \\
    \end{tabular}\end{center}
    \end{table}
       
    Ahora, en base a los datos arrojados por la tabla de arriba, generamos diversas transformaciones de variables, así como la creación de la variable ``Target'', pues es la que usaremos para todo el análisis:
    \begin{itemize}
        \item Creamos la variable ``Target'' y le asignamos la varibale ``nivel\_max\_educativo''.
        \item En la variable ``Target'', reducimos su dimensionalidad intercambiando los valores:
            \begin{itemize}
                \item ``Secundario/medio comun'' y ``EGB (1° a 9° año)'' por ``sec\_completo'',
                \item ``Primario especial'' y ``Primario comun'' por ``prim\_completo'',
                \item ``Sala de 5'' por ``incial'',
                \item ``Otras escuelas especiales" por ``superior'',
                \item y por último a ``No corresponde'' por nulos.
            \end{itemize}
        \item Remplazamos los valores de ``años\_escolaridad'' para que todos sean numéricos.
        \item En la variable ``cantidad\_hijos\_nac\_vivos'' cambiamos el valor ``no corresponde'' como nulo, para luego cambiar el tipo de variable a entero.
        \item Las variables ``comuna'', ``id'', ``nhogar'' y ``miembro'' son de tipo numérico, pero deberían ser categóricas, por lo tanto transformamos su tipo a string.
        \item Por último renombramos algunas variables para que sean más cortas:
            \begin{itemize}
                \item ``dominio\_Villas\_de\_emergencia'' por ``dominio\_villas'',
                \item ``ingreso\_per\_capita\_familiar" por ``ing\_per\_cap\_familiar'',
                \item ``cantidad\_hijos\_nac\_vivos'' por ``cant\_hijos\_nac\_vivos''.
            \end{itemize}
    \end{itemize}
 
    A continuación detallamos un diccionario de las variables:
    \begin{itemize}
        \item \textbf{``id''}                            : Clave que identifica la vivienda,
        \item \textbf{``nhogar''}                        : La variable id + nhogar = clave que identifica a cad hogar",
        \item \textbf{``miembro''}                       : Variables id + nhogar + miembro = clave que identifica  cada persona",
        \item \textbf{``comuna''}                        : Comuna donde reside la persona encuestada,
        \item \textbf{``edad''}                          : Edad de la persona encuestada,
        \item \textbf{``sexo''}                          : Sexo de la persona encuestada,
        \item \textbf{``parentesco\_jefe''}              : Parentesco entre la persona encuestada y el jefe d'' hoga,
        \item \textbf{``situacion\_conyugal''}           : Situación conyugal de la persona encuestada,
        \item \textbf{``num\_miembro\_padre''}           : Número de miembro que corresponde al padre,
        \item \textbf{``num\_miembro\_madre''}           : Número de miembro que corresponde a la madre,
        \item \textbf{``estado\_ocupacional''}           : Situación ocupacional de la persona encuestada,
        \item \textbf{``cat\_ocupacional''}              : Categoría ocupacional de la persona encuestada,
        \item \textbf{``calidad\_ingresos\_lab''}        : Calidad de la declaración de ingresos laborales totales,
        \item \textbf{``ingreso\_total\_lab''}           : Ingreso total laboral percibido el mes anterior,
        \item \textbf{``calidad\_ingresos\_no\_lab''}    : Calidad de la declaración de ingresos no laborale totales",
        \item \textbf{``ingreso\_total\_no\_lab''}       : Ingreso total no laboral percibido el mes anterior,
        \item \textbf{``calidad\_ingresos\_totales''}    : Calidad de ingresos totales individuales,
        \item \textbf{``ingresos\_totales''}             : Ingreso total individual percibido el mes anterior,
        \item \textbf{``calidad\_ingresos\_familiares''} : Calidad de ingresos totales familiares,
        \item \textbf{``ingresos\_familiares''}          : Ingresos totales familiares percibido el mes anterior,
        \item \textbf{``ing\_per\_cap\_familiar''}       : Ingreso familiar per capita percibido el mes anterior,
        \item \textbf{``estado\_educativo''}             : Asistencia (pasada o presente) o no a algú establecimiento educativo",
        \item \textbf{``sector\_educativo''}             : Sector al que pertenece el establecimiento educativo a que asiste",
        \item \textbf{``nivel\_actual''}                 : Nivel cursado al momento de la encuesta,
        \item \textbf{``nivel\_max\_educativo''}         : Máximo nivel educativo que se cursó,
        \item \textbf{``años\_escolaridad''}             : Años de escolaridad alcanzados,
        \item \textbf{``lugar\_nacimiento''}             : Lugar de nacimiento de la persona encuestada,
        \item \textbf{``afiliacion\_salud''}             : Afiliación de salud de la persona encuestada,
        \item \textbf{``hijos\_nacidos\_vivos''}         : Tiene o tuvo hijos nacidos vivos,
        \item \textbf{``cant\_hijos\_nac\_vivos''}       : Cantidad de hijos nacidos vivos,
        \item \textbf{``dominio''}                       : ¿la vivienda se ubica en una villa de emergencia?,
        \item \textbf{``Target''}                        : Nivel máximo educativo.
    \end{itemize}
 
   Y comenzamos el analisis EDA del mismo, primero analizando los nulos:

    \begin{center}
        \includegraphics[scale=0.25]{Imagenes/NullsDS.png}
    \end{center}
 
    Así, detectamos que nuestra variable target tiene 1054 valores nulos. Es importante tener este dato presente cuando queramos correr un algoritmo de clasificación.
 
    \subsection{Análisis univariado}
 
        \subsubsection{Género y edad}
           
            Comenzamos con un pantallazo general sobre las primeras cualidades de los datos, como muestra representativa para la EPH, sobre quiénes son los ciudadanos representados en el dataset.
           
            \begin{center}
                \includegraphics[scale=0.45]{Imagenes/AUGenero.png}    
            \end{center}
           
 
            En la variable género los datos parecen equilibrados en las categorías. Para el caso de la variable ``edad'', la distribución se asemeja a la de una normal.
           
            \subsubsection{Comuna}
           
            Seguimos observando la variable ``comuna''. En la misma se muestra la comuna de la Ciudad de Buenos Aires del entrevistado, de manera de tener una ubicación geográfica. Consideramos importante revisar esta variable ya que tenemos como hipótesis que el nivel educativo alcanzado puede estar dependiendo de la zona geográfica de la ciudad en la que se encuentra el entrevistado.
           
            Para esto vamos a generar un mapa, así que utilizaremos el mapa de comunas de la Ciudad de Buenos Aires, transformamos las variables que vamos a usar para joinear el mapa con la base de manera que coincidan, transformamos la base para contabilizar la frecuencia con la que aparece cada comuna en la base. Y por último unimos ambos datasets y generamos una nueva variable con las coordenadas para poder agregar etiquetas en el centro geográfico de cada comuna, que nos da como resultado los siguientes gráficos:
           
            \begin{center}
                \includegraphics[scale=0.30]{Imagenes/AUComuna.png}    
            \end{center}
 
            Observando ambos gráficos vemos que las comunas 1,4,7 y 8 tienen mayor cantidad de casos. Queda por verse si en posteriores análisis es necesario abordar esta diferencia para evitar sesgos. Para eso, será necesario tomar en cuenta el porcentaje de la población total de cada comuna.
           
            \subsubsection{Ingreso familiar per cápita}
           
            Ahora probamos con observar los ingresos familiares. Creemos que puede ser un indicador interesante del nivel educativo.
           
            Para esto, armamos una función para graficar y jugar con el nivel del filtrado de la variable y obtener un histograma que permita apreciar mejor la distribución de la variable sin tantos outliers:
           
            \begin{center}
                \includegraphics[scale=0.325]{Imagenes/AUIngFam.png}
            \end{center}
           
            % Y como hay muchos outliers que impiden ver la distribución correctamente, los quitamos de los gráficos:
           
            % \includegraphics[scale=0.4]{Graf5.png}
 
            Y luego de remover los outliers la distribución de los ingresos familiares sigue estando \textbf{sesgada}.
 
            \newpage

            \subsubsection{Años de escolaridad}
           
            Analizamos mediante un gráfico de barras los años de escolaridad alcanzados por los encuestados:
           
            \begin{center}
                \includegraphics[scale=0.6]{Imagenes/AUAnosEsc.png}
            \end{center}
           
            A simple vista se observan tres "picos": en el valor mínimo, alrededor del 7.5 y alrededor del 12.5. Podemos inferir que estos tres casos corresponden a no tener estudios, solo haber transcurrido el primario y haber transcurrido hasta la educación secundaria, respectivamente.
           
            \subsubsection{Máximo nivel educativo (Target)}
           
            \begin{center}
                \includegraphics[scale=0.3]{Imagenes/AUTarget.png}    
            \end{center}
           
            Podemos observar que el nivel máximo educativo más alcanzado es el secundario completo, seguido por el primario. Contrario de lo que habíamos intuido anteriormente, el nivel superior quedó en tercer lugar. Adicionalmente, el nivel secundario y primario explican casi el 77\% de los datos.
 
    \newpage

    \subsection{Análisis bivariado}
 
        Para comenzar el análisis bivariado del problema, realizamos diferentes heat maps para ver si algo nos llama la atención entre las variables numéricas.        
       
        \begin{center}
            \includegraphics[scale=0.65]{Imagenes/ABSpearman.png}
        \end{center}
 
        A simple vista, no se observan fuertes correlaciones.
 
        Podemos notar que la variable ``años\_escolaridad'' correlaciona moderadamente bien con variablres relacionadas al ingreso.
 
        La principal correlación positiva es ``años\_escolaridad'' con ingreso familiar per cápita (``ing\_per\_cap\_familiar''), lo cual hace sentido teórico.
 
        Ahora, utilizando el método para solo graficar en base a un threshold vemos que los años de escolaridad alcanzados por los entrevistados tienen algo relación $(66\%$) con la variable ``ingresos\_totales''
        % Estaria bien solo utilizar el grafico de la derecha.

        \begin{center}
            \includegraphics[scale=0.4]{Imagenes/ABThreshold.png}
        \end{center}
 
        Por último corremos una tabla de correlación y filtramos las de valores más altos
 
        \begin{table}[H]
            \centering
            \begin{tabular}{|l|l|l|l|}
            \hline
                ~ & Variable\_1 & Variable\_2 & corr\_value \\ \hline
                2 & ingreso\_total\_lab & ingresos\_totales & 0.80 \\ \hline
                6 & ingresos\_familiares & ing\_per\_cap\_familiar & 0.76 \\ \hline
                4 & ingresos\_totales & ing\_per\_cap\_familiar & 0.62 \\ \hline
                5 & ingresos\_totales & años\_escolaridad & 0.60 \\ \hline
                1 & edad & ingreso\_total\_no\_lab & 0.57 \\ \hline
                7 & años\_escolaridad & Target & 0.57 \\ \hline
                3 & ingreso\_total\_lab & años\_escolaridad & 0.54 \\ \hline
            \end{tabular}
        \end{table}
 
        \textbf{Conclusiones:}
        \begin{itemize}
            \item Como es esperable, hay alta correlación entre las variables relacionadas al ingreso.
            \item A su vez, encontramos una alta correlación (66\%) entre los ingresos y los años de escolaridad.
            \item También observamos una relación positiva entre la edad y los ingresos totales.
        \end{itemize}
 
        \subsubsection{Comparación entre variables numéricas}
 
            \begin{center}
                \includegraphics[scale=0.2]{Imagenes/ABCompVarNum.png}
            \end{center}
 
            Se puede ver que desde los 30 años en adelante el ingreso total de la persona se corresponde con el ingreso familiar. Por ende suele haber un único ingreso fuerte por grupo familiar.
 
        \subsubsection{Comparación de variables categóricas con numéricas}
 
            Adicionalmente, vamos a comparar algunas variables con nuestro target, comenzando con los ingresos totales.
 
            \begin{center}
                \includegraphics[scale=0.225]{Imagenes/ABCatVsNum1.png}
            \end{center}
 
            Probemos quitando outliers, a excepción de la cantidad de hijos nacidos vivos (puesto que no arrojará ningún dato nuevo) y de años de escolaridad (que no tiene outliers)
 
            \begin{center}
                \includegraphics[scale=0.425]{Imagenes/ABCatVsNum2.png}
            \end{center}
 
            Por parte de las variables de ingreso, no parece haber nada disruptivo. La distribución por ingreso y años de escolaridad pareciera ocurrir pero no en un orden lineal.
 
            Llama la atención la variable "sexo": por algún motivo, todos los encuestados hombres figuran sin hijos nacidos vivos. Alternativamente, se podría investigar la metodología de la encuesta para ver si hay alguna respuesta. Adicionalmente, los hombres parecieran tener ingresos totales y familiares mayores que las mujeres, pero no pareciera que haya distribuciones desiguales en los años de escolaridad.
 
            \begin{center}
                \includegraphics[scale=0.3]{Imagenes/ABCatVsNum3Bis.png}
            \end{center}
 
            Parece que para el nivel inicial la remoción de outliers en otra categoría sigue siendo insuficiente para mostrar la distribución real de la variable. Echemos un vistazo a los valores de esta categoría.
 
            \begin{center}
                \includegraphics[scale=0.8]{Imagenes/ABCatVsNum4.png}
            \end{center}
 
            Lógicamente, la enorme mayoría de los ingresos tienen el valor inicial de 0, puesto que incluye a personas que en ese momento estaban cursando su educación inicial, por lo que tenían entre 2 y 6 años.
 
            \begin{center}
                \includegraphics[scale=0.3]{Imagenes/ABCatVsNum5.png}
            \end{center}
 
            En definitiva, se observa un corrimiento de los valores centrales (dentro de la caja) hacia la izquierda a medida que aumenta el nivel educativo.
 
        \subsubsection{Variable numéricas con comuna}
 
            \begin{center}
                \includegraphics[scale=0.65]{Imagenes/ABCatVsNum6.png}
            \end{center}
 
            Se observa que en el sur de la ciudad hay  mayor cantidad de encuestados con niveles de inicial, primario y secundario completo, mientras que el norte (particularmente el barrio de Palermo) tiene mayor cantidad de personas con estudios superiores. En menor medida también las comunas del este (comúnmente llamado el "centro" de la ciudad) destacan por la cantidad de encuestados con nivel superior.
 
            \begin{center}
                \includegraphics[scale=0.65]{Imagenes/ABCatVsNum7.png}
            \end{center}
 
            Lo que podemos observar en los últimos dos gráficos es una clara división geográfica del nivel educativo:
            \begin{itemize}
                \item Las comunas del norte son las que tienen mayor nivel educativo.
                \item Las comunas del centro tienen niveles medios.
                \item Las comunas del sur (con las comuna 6 en el centro de la ciudad como outlier) y la comuna 1 en el este son las que tienen niveles más bajos.
            \end{itemize}
           
    \subsection{Análisis multivariado}
 
        Probamos de cruzar años de escolaridad, nivel máximo educativo y los ingresos totales.
 
        \begin{center}
            \includegraphics[scale=0.65]{Imagenes/AMIngVsAnosEsc.png}
        \end{center}
 
        \textbf{Conclusiones de la visualización:}
 
        \begin{itemize}
            \item Hasta los 6 años, como era esperable, todos los casos llegan al nivel inicial.
            \item Vemos dos años en que aparece el primario completo: 7 y 12 años. Estimamos que se debe a la división entre los que comenzaron su educación en la primaria y los que comenzaron en el nivel inicial.
            \item A partir de los 12 años vemos un aumento consistente de los ingresos totales.
        \end{itemize}
 
        \begin{center}
            \includegraphics[scale=0.25]{Imagenes/AMIngVSTargetBis.png}
        \end{center}
 
        Aquí obtuvimos un descubrimiento interesante: no importa el nivel máximo educativo, los casos que no provienen de villas de emergencia (dominio=``villas\_de\_emergencia'') obtienen en promedio ingresos más altos en todos los niveles educativos. El alcanzar estudios superiores no parece homogeneizar ambos conjuntos. Esto se puede observar en el segundo gráfico, ya que el violín naranja acumula mayor cantidad de casos hacia la derecha, en comparación con los violines azules que tienen una mayor distribución.
 
        \begin{center}
            \includegraphics[scale=0.6]{Imagenes/AMIngVsComuna.png}
        \end{center}
 
        Aquí podemos observar que a medida que avanza el nivel educativo máximo se atenúan levemente las diferencias de ingresos familiares entre comunas. Queda pendiente cruzar estos datos con la edad, para saber si el hecho de incluir a menores de edad está sesgando los valores para nivel inicial, primario y secundario.
 
\section{Modelos analíticos}

    Comenzamos transformando algunas variables para poder trabajar con los algoritmos:
    \begin{itemize}
        \item recategorizando la variables "Target" en variables numéricas,
        \item reagrupamos la variable "comuna" por regiones para reducir la dimensionalidad,
        \item y por último renombramos algunas variables para que sean más cortas.
    \end{itemize}

    Como resultado nos quedan las siguientes variables:
    
    \begin{table}[H]
        \centering
        \begin{tabular}{clll}
            \multicolumn{4}{l}{RangeIndex: 14319 entries, 0 to 14318} \\
            \multicolumn{4}{l}{Data columns (total 33 columns):} \\
            \#  & features & types & non\_null\_counts \\ \hline 
            0   & id & object & 14319 \\ 
            1   & nhogar & object & 14319 \\ 
            2   & miembro & object & 14319 \\ 
            3   & comuna & object & 14319 \\ 
            4   & dominio & object & 14319 \\ 
            5   & edad & int64 & 14319 \\ 
            6   & sexo & object & 14319 \\ 
            7   & parentesco\_jefe & object & 14319 \\ 
            8   & situacion\_conyugal & object & 14318 \\ 
            9   & num\_miembro\_padre & object & 14319 \\ 
            10  & num\_miembro\_madre & object & 14319 \\ 
            11  & estado\_ocupacional & object & 14319 \\ 
            12  & cat\_ocupacional & object & 14319 \\ 
            13  & calidad\_ingresos\_lab & object & 14319 \\ 
            14  & ingreso\_total\_lab & int64 & 14319 \\ 
            15  & calidad\_ingresos\_no\_lab & object & 14319 \\ 
            16  & ingreso\_total\_no\_lab & int64 & 14319 \\ 
            17  & calidad\_ingresos\_totales & object & 14319 \\ 
            18  & ingresos\_totales & int64 & 14319 \\ 
            19  & calidad\_ingresos\_familiares & object & 14319 \\ 
            20  & ingresos\_familiares & int64 & 14319 \\ 
            21  & ing\_per\_cap\_familiar & int64 & 14319 \\ 
            22  & estado\_educativo & object & 14319 \\ 
            23  & sector\_educativo & object & 14316 \\ 
            24  & nivel\_actual & object & 14319 \\ 
            25  & nivel\_max\_educativo & object & 13265 \\ 
            26  & años\_escolaridad & float64 & 14257 \\ 
            27  & lugar\_nacimiento & object & 14318 \\ 
            28  & afiliacion\_salud & object & 14315 \\ 
            29  & hijos\_nacidos\_vivos & object & 6535 \\ 
            30  & cant\_hijos\_nac\_vivos & int64 & 14319 \\ 
            31  & Target & Int64 & 13223 \\ 
            32  & region & object & 14319 \\
            \multicolumn{4}{l}{dtypes: Int64(1), float64(1), int64(7), object(24)} \\
            \multicolumn{4}{l}{memory usage: 3.6+ MB } \\
        \end{tabular}
    \end{table}

    \subsection{Tratados de nulos}

        En primer lugar, armamos una función para tener una lista limpia de variables con nulos, que nos da como resultado:

        \begin{table}[H]
            \begin{tabular}{lr}
                situacion\_conyugal & 1 \\ 
                lugar\_nacimiento & 1 \\ 
                sector\_educativo & 3 \\ 
                afiliacion\_salud & 4 \\ 
                años\_escolaridad & 62 \\ 
                nivel\_max\_educativo & 1054 \\ 
                Target & 1096 \\ 
                hijos\_nacidos\_vivos & 7784 \\ 
            \end{tabular}
        \end{table}

        Entonces, para eliminar los valores nulos de la variable ``años\_escolaridad'' reemplazamos los nulos con la mediana por comuna y sexo.

        Por otro lado, a los nulos las variables:
        \begin{itemize}
            \item ``lugar\_nacimiento'',
            \item ``situacion\_conyugal'',
            \item ``afiliacion\_salud'',
            \item ``sector\_educativo''
            \item ``hijos\_nacidos\_vivos''
        \end{itemize}
        los reemplazamos con la moda.
        
        Luego, elimios la variable ``nivel\_max\_educativo'' ya que no la vamos a utilizar y por último eliminamos los nulos de nuestro target y pasamos el tipo de dato de la misma a entero. 
        

    \subsection{Target}

        \subsubsection{Borrado de variables}
    
        Hay muchas variables que consideramos que no es necesario sumarlas al algoritmo de clasificacion dado que brindan información repetida o que no suma para la clasificación. A continuación se comparten las categoria que se descartarán para correr el algoritmo: 
        \begin{itemize}
            \item \textbf{id:} no suma información para la clasificación,
            \item \textbf{nhogar:} no suma información para la clasificación,
            \item \textbf{parentesco\_jefe:} no suma información para la clasificación,
            \item \textbf{miembro:} no suma información para la clasificación,
            \item \textbf{num\_miembro\_padre:} no suma información para la clasificación,
            \item \textbf{num\_miembro\_madre:} no suma información para la clasificación,
            \item \textbf{cat\_ocupacional:} brinda la misma información que estado\_ocupacional,
            \item \textbf{calidad\_ingresos\_lab:} brinda la misma información que ingreso\_total\_lab,
            \item \textbf{calidad\_ingresos\_no\_lab:} brinda la misma información que ingreso\_total\_no\_lab,
            \item \textbf{calidad\_ingresos\_totales:} brinda la misma información que ingresos\_totales,
            \item \textbf{calidad\_ingresos\_familiares:} brinda la misma información que ingreso\_familiares,
            \item \textbf{estado\_educativo:} no aporta información para la clasificación,
            \item \textbf{nivel\_actual:} no aporta información para la clasificacion,
            \item \textbf{hijos\_nacidos\_vivos:} brinda la misma información que cant\_hijos\_nac\_vivos,
            \item \textbf{comuna:} variable ya abordada en la variable 'región'.
        \end{itemize}

        Y como resultado, tenemos nuestro dataset listo para el procesamiento:

        \begin{table}[H]
            \centering
            \begin{tabular}{clll}
                \multicolumn{4}{l}{RangeIndex: 14319 entries, 0 to 14318} \\
                \multicolumn{4}{l}{Data columns (total 18 columns):} \\
                \# & features & types & non\_null\_counts \\ \hline
                0  & dominio & object & 14319 \\ 
                1  & edad & int64 & 14319 \\ 
                2  & sexo & object & 14319 \\ 
                3  & situacion\_conyugal & object & 14318 \\ 
                4  & estado\_ocupacional & object & 14319 \\ 
                5  & ingreso\_total\_lab & int64 & 14319 \\ 
                6  & ingreso\_total\_no\_lab & int64 & 14319 \\ 
                7  & ingresos\_totales & int64 & 14319 \\ 
                8  & ingresos\_familiares & int64 & 14319 \\ 
                9  & ing\_per\_cap\_familiar & int64 & 14319 \\ 
                10  & sector\_educativo & object & 14316 \\ 
                11  & nivel\_max\_educativo & object & 13265 \\ 
                12  & años\_escolaridad & float64 & 14257 \\ 
                13  & lugar\_nacimiento & object & 14318 \\ 
                14  & afiliacion\_salud & object & 14315 \\ 
                15  & cant\_hijos\_nac\_vivos & int64 & 14319 \\ 
                16  & Target & Int64 & 13223 \\ 
                17  & region & object & 14319 \\ 
                \multicolumn{4}{l}{dtypes: Int64(1), float64(1), int64(7), object(9)} \\
                \multicolumn{4}{l}{memory usage: 2.0+ MB} 
            \end{tabular}
        \end{table}
    \subsection{Procesamiento}

        Para preparar los datos para el modelado generamos una función que:
        \begin{itemize}
            \item  Divide el dataframe en X\_train, y\_train, X\_test e y\_test, haciendo la división entre test y el train en un 30\% y un 70\% respectivamente, con una semilla especifica.
            \item  Procesa el X\_train y el X\_test con un pipeline generado previamente, el cual convierte las variable numéricas con el minmaxscaler y las categóricas con one hot encoding.
        \end{itemize}

        Una vez aplicada dicha función a nuestro dataframe, tenemos ya lista la particion (con la misma cantidad de columnas) del mismo en X\_train, y\_train, X\_test e y\_test.

    \subsection{Árbol de decisión}

        \subsubsection{Primer modelo}

            Como primera aproximación, vamos a usar un arbol de clasificación usando con parametros:
            \begin{itemize}
                \item random\_state = 50,
                \item max\_depth=8,
            \end{itemize}
            para saber como performa y mejorarlo a partir de ahí.

            Donde el Accuracy score para el test es de: 0.940 y la matriz de confusión da:
            \begin{table}[H]
                \centering
                \begin{tabular}{|l|c|c|c|c|}
                \hline
                    ~ & Predicc. Inicial & Predicc. Primario & Predicc. Secundario & Predicc. Superior \\ \hline
                    Inicial & 445 & 0 & 1 & 0 \\ \hline
                    Primario & 0 & 961 & 8 & 9 \\ \hline
                    Secundario & 0 & 19 & 1693 & 59 \\ \hline
                    Superior & 1 & 57 & 84 & 630 \\ \hline
                \end{tabular}
            \end{table}

            \begin{table}[H]
                \centering
                \begin{tabular}{rrrrr}
                    ~ & precision & recall & f1-score & support \\ 
                    & & & & \\
                    1 & 0.9977578475336323 & 0.9977578475336323 & 0.9977578475336323 & 446 \\ 
                    2 & 0.926711668273867 & 0.9826175869120655 & 0.9538461538461539 & 978 \\ 
                    3 & 0.9479283314669653 & 0.955957086391869 & 0.9519257801518133 & 1771 \\ 
                    4 & 0.9025787965616046 & 0.8160621761658031 & 0.8571428571428572 & 772 \\ 
                    & & & & \\
                    accuracy &  &  & 0.9400050415931435 & 3967 \\ 
                    macro avg & 0.9437441609590171 & 0.9380986742508424 & 0.9401681596686141 & 3967 \\ 
                    weighted avg & 0.939474645209326 & 0.9400050415931435 & 0.9391067256931398 & 3967 \\ 
                \end{tabular}
            \end{table}

            A simple vista, parece que el modelo performa muy bien, dado su accuracy. Veamos más en detalle:

            Pero antes, calculemos su sesgo y su varianza:

            El promedio de score en el train es  0.96889

            El score minimo es 0.930

            El maximo score es 0.989

            Cross validation score es  0.96337 ± 0.02

            El test score es  0.94001 

            ------------------------------------------

            La varianza tiene un valor de 0.0289

            El sesgo tiene un valor de 0.9689

            \textbf{Conclusiones:}
            \begin{itemize}
                \item \textbf{Bias o sesgo:} 96.89\% que nos indica que tengo poco error. $\Rightarrow$ low bias,
                \item \textbf{Variance=Test\_Score - Bias=} 2.89\%  $\Rightarrow$ low variance.
            \end{itemize}

            \textbf{El modelo tiene una buena relación de sesgo y varianza.}

            De aqui, vemos necesario ver cuáles son las variables más importantes para el armado del modelo. Esto nos permitirá volver el modelo más robusto, al quitar las mismas. 

            Y como resultado, tenemos que la variable ``años\_escolaridad'' tiene una importancia del 84\%, por mucho superior al resto de variables.

            % Tendiramos que agregar algo relacionado a la diferencia que tenemos con los resultado del EDA.

            Por lo tanto, vamos a tener que desarrollar un nuevo modelo sin esta variable. El principal motivo es que los años de escolaridad es un dato que puede contastarse de forma conjunta con el nivel máximo educativo, por lo que tiene sentido que si no tenés la variable target, tampoco tengas la variable de los años de escolaridad.

            Así, creamos un dataset nuevo (llamado ``df2'') sin la variable ``años\_escolaridad'', para volver a aplicar la función ``procesador'' para dividir nuevamente el mismo y generar nuevos modelos.

        \subsubsection{Segundo modelo}

            Esta vez al correr el modelo, utilizaremos el ``DecisionTreeClassifier'' solo con el parametro random\_state = 50. Que nos da como resultado:  

            \begin{table}[!ht]
                \centering
                \begin{tabular}{rrrrr}
                    ~ & precision & recall & f1-score & suppo \\ 
                    & & & & \\
                    1 & 0.822429906542056 & 0.7892376681614349 & 0.8054919908466819 & 446 \\ 
                    2 & 0.46496815286624205 & 0.22392638036809817 & 0.30227743271221535 & 978 \\ 
                    3 & 0.5658379373848987 & 0.6939582156973462 & 0.6233832107532337 & 1771 \\ 
                    4 & 0.38504464285714285 & 0.44689119170984454 & 0.4136690647482014 & 772 \\ 
                    & & & & \\
                    accuracy & & & 0.5407108646332242 & 3967 \\ 
                    macro avg & 0.559570159912585 & 0.5385033639841809 & 0.5362054247650831 & 3967 \\ 
                    weighted avg & 0.5346347474704592 & 0.5407108646332242 & 0.5238822640130464 & 3967 \\ 
                \end{tabular}
            \end{table}

            El promedio de score en el train es  1.00000
            
            El score minimo es 0.497
            
            El maximo score es 0.638
            
            Cross validation score es  0.56310 ± 0.03
            
            El test score es  0.54147 
            
            ------------------------------------------
            
            La varianza tiene un valor de 0.4585
            
            El sesgo tiene un valor de 1.0

            \textbf{Conclusiones:}
            \begin{itemize}
                \item \textbf{Bias o sesgo:} 100\% que nos indica que tengo poco error. $\Rightarrow$ low bias,
                \item \textbf{Variance=Test\_Score - Bias=} 44.97\% $\Rightarrow$ high variance,
            \end{itemize}
            
            \textbf{OVERFITTING}

            Por lo que se observa, el árbol performa bastante peor sin esta variable, aumentando especialmente la varianza. Por lo tanto optamos probar mejorar nuestro modelo con un grid search.
        
        \subsubsection{Gridsearch con CV}
            
            En la grilla de parametros para el Gridsearch elegimos los siguientes:
            \begin{itemize}
                \item 'max\_depth': range(5,11),
                \item 'max\_features': range(1,14);
            \end{itemize}
            como estimador el ``DecisionTreeClassifier'' con el random\_state=50, con el cross-validation =10,  usando todos los precesadores.

            Y nos da como resultado, que el mejor arbol de decisión posible obtiene 0.642. Y para eso el arbol debe tener una profundidad de  6  y utilizar  10  variables.

            Entonces, entrenamos el modelo bajo estos mismos parametros y obtenemos el siguiente reporte de clasificación:

            \begin{table}[H]
                \centering
                \begin{tabular}{rrrrr}
                    ~ & precision & recall & f1-score & support \\ 
                    & & & & \\
                    1 & 0.993993993993994 & 0.742152466367713 & 0.8498074454428755 & 446 \\ 
                    2 & 0.4940898345153664 & 0.21370143149284254 & 0.2983583154889365 & 978 \\ 
                    3 & 0.5450017787264319 & 0.8650479954827781 & 0.6687036228721082 & 1771 \\ 
                    4 & 0.7825 & 0.405440414507772 & 0.5341296928327646 & 772 \\ 
                    & & & & \\
                    accuracy & & & 0.601209982354424 & 39 \\ 
                    macro avg & 0.703896401808948 & 0.5565855769627764 & 0.5877497691591711 & 3967 \\ 
                    weighted avg & 0.6291478017650266 & 0.601209982354424 & 0.5715731767555079 & 3967 \\ 
                \end{tabular}
            \end{table}

            El promedio de score en el train es  0.65266
            
            El score minimo es 0.508

            El maximo score es 0.724

            Cross validation score es  0.63742 ± 0.04

            El test score es  0.60121 

            ------------------------------------------

            La varianza tiene un valor de 0.0514

            El sesgo tiene un valor de 0.6527
            \begin{itemize}
                \item \textbf{Bias o sesgo:} 61.8\% que nos indica que tengo bastantes errores $\Rightarrow$ high bias,
                \item \textbf{Variance=Test\_Score - Bias==} 3.67\%  $\Rightarrow$ low variance.
            \end{itemize}

            \textbf{UNDERFITTING}

            \textbf{Conclusiones}
            
            Utilizar el grid search nos permitió mejorar bastante el modelo que había perdido bastante accuracy al retirar los años de escolaridad. La métrica que más pudimos mejorar con este método fue la varianza, que pasó de 45\% a 5\%.

    \subsection{Random Forest Classifier}
        
        Ahora vamos a trabajar con random forest, para saber si este algoritmo nos arroja mejores resultados. Y teniendo en cuento todo el dataset incluido la variable con los años de escolaridad. 

        \subsubsection{Primer modelo}

            Como primer modelo con el Random Forest Classifier, elegimos los siguientes parametros:
            \begin{itemize}
                \item n\_estimators=200,
                \item max\_depth=15,
                \item random\_state=50.
            \end{itemize}

            Que nos da los siguientes resultados:
            \begin{table}[H]
                \centering
                \begin{tabular}{rrrrr}
                \hline
                    ~ & precision & recall & f1-score & support \\ 
                    & & & & \\
                    1 & 1.0 & 0.9596412556053812 & 0.9794050343249427 & 446\\ 
                    2 & 0.8585951940850277 & 0.9498977505112475 & 0.9019417475728155 & 978\\ 
                    3 & 0.9055982436882547 & 0.9316770186335404 & 0.9184525466184248 & 1771\\ 
                    4 & 0.9244094488188976 & 0.7603626943005182 & 0.8343994314143568 & 772\\ 
                    & & & & \\
                    accuracy & & & 0.9059742878749685 & 3967 \\ 
                    macro avg & 0.9221507216480451 & 0.9003946797626718 & 0.9085496899826351 & 3967\\ 
                    weighted avg & 0.9082845182443269 & 0.9059742878749685 & 0.904877614204248 & 3967\\ 
                \end{tabular}
            \end{table}

            El random forest performa bastante bien, de todas maneras buscamos cuales son las variables más importantes, y encontramos que los años de escolaridad redujo la enorme importancia (a un 41\%) que tenía en el random tree. Sin embargo, sigue correspondiendo quitarla del modelo.

        \subsubsection{Segundo modelo}

            En este caso elegimos los siguientes parametros:
            \begin{itemize}
                \item n\_estimators=200,
                \item max\_depth=10,
                \item random\_state=50.
            \end{itemize}

            Dondonos por resultado los siguientes medidas de desempeño:
            \begin{table}[H]
                \centering
                \begin{tabular}{rrrrr}
                    ~ & precision & recall & f1-score & support \\ 
                    & & & & \\
                    1 & 0.9486486486486486 & 0.7869955156950673 & 0.8602941176470589 & 446 \\
                    2 & 0.570694087403599 & 0.22699386503067484 & 0.3247988295537673 & 978 \\
                    3 & 0.5623014472290858 & 0.8994918125352908 & 0.6920069504778453 & 1771 \\
                    4 & 0.832 & 0.40414507772020725 & 0.5440278988666085 & 772 \\
                    & & & & \\
                    accuracy & 0.624653390471389 & & & 3967 \\
                    macro avg & 0.7284110458203333 & 0.5794065677453101 & 0.60528194913632 & 3967 \\
                    weighted avg & 0.6602913984927472 & 0.624653390471389 & 0.5916002719928053 & 3967 \\
                \end{tabular}
            \end{table}

            El promedio de score en el train es  0.73552
            
            El score minimo es 0.535
            
            El maximo score es 0.724
            
            Cross validation score es  0.66065 ± 0.04
            
            El test score es  0.62465 
            
            ------------------------------------------
            
            La varianza tiene un valor de 0.1109
            
            El sesgo tiene un valor de 0.7355

            El modelo empeora su accuracy pero está muy cercano al mejor modelo de Random Tree. Probemos mejorándolo con grid search.

        \subsubsection{Gridsearch con CV}

            En la grilla de parametros para el Gridsearch elegimos los siguientes parametros:
            \begin{itemize}
                \item 'max\_depth': [5,7,10,15,None],
                \item 'max\_features': [5,8,10,30,41],
                \item 'n\_estimators': [200,300,500].
            \end{itemize}
            como estimador el ``RandomTreeClassifier'' que utlizamos en el último modelo, con el cross-validation =10 y  usando todos los precesadores.

            Y nos da como resultado, que el mejor random forest posible obtiene 0.668. 

            Y para eso el arbol debe tener una profundidad de  15 , utilizar  10  variables y tener  300  estimadores
            
            Entonces, entrenamos el modelo bajo estos mismos parametros y obtenemos el siguiente reporte de clasificación:

            \begin{table}[!ht]
                \centering
                \begin{tabular}{rrrrr}
                    ~ & precision & recall & f1-score & support \\
                    & & & & \\
                    1 & 0.9486486486486486 & 0.7869955156950673 & 0.8602941176470589 & 446 \\
                    2 & 0.5612745098039216 & 0.23415132924335377 & 0.3304473304473304 & 978 \\
                    3 & 0.5618298784846318 & 0.8876341050254094 & 0.6881155613919895 & 1771 \\
                    4 & 0.7979539641943734 & 0.40414507772020725 & 0.5365434221840069 & 772 \\
                    & & & & \\
                    accuracy & & & 3967 \\
                    macro avg & 0.7174267502828938 & 0.5782315069210094 & 0.6038501079175964 & 3967 \\
                    weighted avg & 0.6511330837004972 & 0.6211242752709857 & 0.5897990538944653 & 3967 \\
                \end{tabular}
            \end{table}

            El promedio de score en el train es  0.90655
            
            El score minimo es 0.630
            
            El maximo score es 0.706
            
            Cross validation score es  0.66454 ± 0.02
            
            El test score es  0.62112 
            
            ------------------------------------------
            
            La varianza tiene un valor de 0.2854
            
            El sesgo tiene un valor de 0.9065
            
            \textbf{Conclusiones:}
            \begin{itemize}
                \item \textbf{Bias o sesgo:} 90.65\% que nos indica que tengo bastantes errores $\Rightarrow$ low bias
                \item \textbf{Variance=Test\_Score - Bias==} 28\% $\Rightarrow$ high variance
            \end{itemize} 

\section{Conclusiones}

    Finalmente, nos queda elegir el mejor modelo para realizar nuestras predicciones. Para eso vamos a tomar las métricas de cada uno de ellos y hacer un cuadro comparativo:
    
    \begin{table}[H]
        \centering
        \begin{tabular}{|l|r|r|r|}
        \hline
            modelo & accuracy & sesgo & varianza \\ \hline
            arbol\_default & 0.5407108646332242 & 0.9978392394122731 & 0.4571 \\ \hline
            arbol\_mejorado & 0.601209982354424 & 0.6526577355229041 & 0.0514 \\ \hline
            bosque\_default & 0.624653390471389 & 0.7355229040622299 & 0.1109 \\ \hline
            bosque\_mejorado & 0.6211242752709857 & 0.9065471045808124 & 0.2854 \\ \hline
        \end{tabular}
    \end{table}

    Con esta información podemos decidir qué modelo nos conviene usar:
    \begin{itemize}
        \item El arbol default tiene el mejor resultado con respecto al sesgo, pero su varianza lo deja afuera de la competencia.
        \item Por el contrario, el arbol mejorado tiene una varianza insuperable de 3\%, aunque con el menor puntaje con respecto al sesgo.
        \item El bosque default tiene resultados mixtos en ambas categorías.
        \item El bosque mejorado destaca por bajo sesgo pero su varianza es la segunda peor.
    \end{itemize}
    Como era de esperarse, los finalistas son el arbol y el bosque mejorado. Sorprendentemente, ambos performan muy bien pero en étricas diferentes. A su vez, el accuracy de ambos difiere en apenas un 4%.

    En nuestra opinión, es el arbol mejorado el ganador, ya que tiene la robustez suficiente para poder generalizar en caso de agregar nuevos datos al modelo.
        
\end{document}